# 1. 进程的基本概念

## 1.1 概念

> 进程是操作系统进行资源分配和调度的基本单位，是一个独立运行的程序实体。每个进程拥有独立的内存空间、文件描述符、寄存器状态等资源。进程之间的资源是相互隔离的，因此进程间通信需要通过操作系统提供的特定机制（如管道、消息队列、共享内存等）进行。由于进程拥有独立的资源，所以进程间的切换和调度开销较大。进程是操作系统进行资源分配和调度的基本单位，是一个独立运行的程序实体。每个进程拥有独立的内存空间、文件描述符、寄存器状态等资源。进程之间的资源是相互隔离的，因此进程间通信需要通过操作系统提供的特定机制（如管道、消息队列、共享内存等）进行。由于进程拥有独立的资源，所以进程间的切换和调度开销较大。

进程是操作系统进行资源分配的基本单位，调度的基本单位在线程出现后，调度的基本单位被线程抢走。进程是操作系统最终的概念，没有进程，就没有OS。

## 1.2 PID与PCB

PID（Process Identification）[操作系统](http://baike.baidu.com/view/880.htm)里指进程识别号，也就是进程标识符。[操作系统](http://baike.baidu.com/view/880.htm)里每打开一个[程序](http://baike.baidu.com/view/17674.htm)都会创建一个进程ID，即PID。

只要运行一程序，系统会自动分配一个标识。 进程中止后，这个号码就会被回收，并可能被分配给另一个新进程。  

如果成功运行一个程序，然后再运行别的程序时，系统会自动分配另一个PID。

进程控制块(PCB)（系统为了管理进程设置的一个专门的数据结构，用它来记录进程的外部特征，描述进程的运动变化过程。系统利用PCB来控和管理进程，所以PCB是系统感知进程存在的唯一标志。进程与PCB是一一对应的）在不同的操作系统中对进程的控制和管理机制不同，PCB中的信息多少不一样，通常PCB应包含如下一些信息。

1. 进程标识符 PID：每个进程都必须有一个唯一的标识符，可以是字符串，也可以是一个数字。

2. 进程当前状态 status：说明进程当前所处的状态。为了管理的方便，系统设计时会将相同的状态的进程组成一个队列，如就绪进程队列，等待进程则要根据等待的事件组成多个等待队列\，如等待打印机队列、等待磁盘I/O完成队列等等。

3. 进程相应的程序和数据地址，以便把PCB与其程序和数据联系起来。

4. 进程资源清单。列出所拥有的除CPU外的资源记录，如拥有的I/O设备)，打开的文件列表等。

5. 进程优先级 priority：进程的优先级反映进程的紧迫程度，通常由用户指定和系统设置。

6. CPU现场保护区 cpustatus：当进程因某种原因不能继续占用CPU时（如等待打印机），释放CPU，这时就要将CPU的各种状态信息保护起来，为将来再次得到处理机恢复CPU的各种状态，继续运行。

7. 进程同步与通信机制 用于实现进程间互斥、同步和通信所需的信号量等。

8. 进程所在队列PCB的链接字 根据进程所处的现行状态，进程相的PCB参加到不同队列中。PCB链接字指出该进程所在队列中下一个进程PCB的首地址。

9. 与进程有关的其他信息。 如进程记账信息，进程占用CPU的时间等。

## 1.3 进程的状态

![进程的状态变化](http://123.57.190.49:12121/api/image/820PJDZV.jpg)

新建:当一个进程刚刚被创建时，它处于新建状态。在这个状态下，操作系统为进程分配必要的资源，如内存、文件描述符等，并初始化进程控制块（PCB）等数据结构。这个状态下进程开始初始化，类似于一个人出生的过程，现在他还处于从娘胎里出来的阶段。

就绪Ready：进程已经准备好运行，正在等待操作系统调度器分配CPU时间片。就绪状态的进程已分配到了除CPU之外的所有必要资源，**只需要CPU时间片**就可以开始执行。

运行Running：进程正在CPU上执行。在任何给定时刻，每个CPU或核心上最多只能有一个进程处于运行状态。

阻塞Blocked：进程因等待某个事件（如I/O操作完成、锁释放或信号到达）而暂停执行。在阻塞状态下，进程无法继续执行，直到等待的事件发生。

终止Terminated：进程已经完成执行或因某种原因被终止。在终止状态下，进程的资源被回收，进程控制块（PCB）可能被保留一段时间以便父进程获取子进程的退出状态。

以上是一个基本概念，不如我们去看一下Linux下进程有哪些状态吧。为什么不用windows，因为他告诉你此进程处于效率模式，你会一脸懵逼，什么是效率模式。

<img src="http://123.57.190.49:12121/api/image/26LZD464.png" title="" alt="" data-align="center">

如图所示，其中STAT为进程的状态。

* **`R` (Running or Runnable)**
  
  * **含义**: 进程正在运行（占用 CPU）或者已经准备就绪，在运行队列中等待被调度执行。
  * **进入原因**: 进程被创建后、从睡眠或停止状态被唤醒后，或者在等待 CPU 时间片时，会进入此状态。对应Ready和Running状态

* **`S` (Interruptible Sleep)**
  
  * **含义**: 进程正在等待某个事件的发生（例如等待 I/O 操作完成、等待信号量、等待网络连接、`sleep()` 调用等）。这种状态的进程可以被信号中断。这是进程最常见的状态之一。
  * **进入原因**: 进程执行了会导致阻塞的系统调用（如 `read()`, `write()`, `select()`, `sleep()`, `wait()`, `pause()` 等），需要等待资源或事件才能继续执行。对应Block状态。

* **`D` (Uninterruptible Sleep)**
  
  * **含义**: 进程通常在等待不可中断的 I/O 操作（通常是磁盘 I/O）。它不能被信号中断，即使是 `SIGKILL` 也不行（直到 I/O 完成）。这种状态是为了防止进程在与硬件交互的关键阶段被中断而导致数据损坏或设备状态不一致。
  * **进入原因**: 进程正在执行一个**不能被中断**的内核代码路径，通常是直接与硬件交互，如等待磁盘读写完成、NFS 操作等。如果进程长时间处于 `D` 状态，通常表示底层硬件或驱动程序存在问题。

* **`T` (Stopped or Traced)**
  
  * **含义**: 进程被暂停执行。
  * **进入原因**:
    * 接收到 `SIGSTOP`, `SIGTSTP` (例如在终端按 `Ctrl+Z`), `SIGTTIN`, `SIGTTOU` 等信号。
    * 进程正在被调试器（如 `gdb`）跟踪 (Traced)。
  * 进程可以通过接收 `SIGCONT` 信号恢复到 `R` 状态。

* **`Z` (Zombie)**
  
  * **含义**: 进程已经终止执行（调用了 `exit()` 或异常终止），但其父进程尚未读取其退出状态（通过 `wait()` 或 `waitpid()` 系统调用）。进程描述符（Process Descriptor）仍然保留在内核中，以便父进程查询其退出原因。
  * **进入原因**: 进程执行完毕或被终止，内核需要通知其父进程并传递退出码。在父进程调用 `wait()` 系列函数之前，子进程就处于僵尸状态。它本身不占用内存和 CPU，只占用内核进程表中的一个条目。大量的僵尸进程通常意味着父进程有 Bug（没有正确处理子进程退出）。

* **`X` (Dead)**
  
  * **含义**: 这是一个很少见的状态，表示进程已经死亡。理论上在 `ps` 的输出中不应该看到这个状态。

**状态修饰符 (通常附加在主状态码之后):**

* `s`: 表示该进程是一个会话领导者 (Session Leader)。
* `+`: 表示该进程位于前台进程组。
* `l`: 表示进程是多线程的 (使用了 `CLONE_THREAD`，内核视角看是轻量级进程 LWP)。
* `N`: 表示进程优先级较低 (niced)。
* `<`: 表示进程优先级较高 (实时进程或未被 nice 降低优先级)。

## 1.4 进程的通信方式

进程间通信（Inter-Process Communication, IPC）是指进程之间通过特定的方式共享数据和信息的过程。在多任务操作系统中进程间通信对于协调进程的执行和实现资源共享非常重要。以下是一些常见的进程间通信方式：进程间通信（Inter-Process Communication, IPC）是指进程之间通过特定的方式共享数据和信息的过程。在多任务操作系统中进程间通信对于协调进程的执行和实现资源共享非常重要。以下是一些常见的进程间通信方式：

**管道**

* 管道是一种单向的IPC，内核中存在一定缓冲区，并且传输的数据是字节流。管道在UNIX中是被当做一个文件，系统调用会提供两个文件描述符供用户读写文件。
* 如果管道的写端没有被进程持有，而收端尝试去读的话，此时会受到EOF，如果写端有进程持有的话，读端就会阻塞在read上。
* 管道分为**命名管道与匿名管道**，匿名管道没有名字，是通过系统调用pipe()创建的,只返回两个文件描述符，注意是pipe[1]写给pipe[0]。因为匿名管道没有名字，所以一般匿名管道只能用于两个关系比较近的进程，比如fork出来的父子进程。
* 当两个关系比较远的时候，此时就应该使用命名管道，创建该管道的命令为mkfifo，需要指定一个全局的文件名与权限，之后读写管道就是在读写这个文件。
* 管道只能单项传输数据，如果想双向传输，那么就用socketpair。socketpair会创建两个socket，父进程关闭一个，子进程关掉另一个。这样双方各拿一个socket通信。

**消息队列**

* 消息队列，是唯一一个以消息为数据抽象的通信方式，消息队列在内核中的数据结构是一个单链表构成的队列，最初会有个消息头部指针，保存着消息队首与相应的权限；每个消息都会有下一个消息的指针，以及消息本身的内容。
* 消息队列的内存空间有限，一般来说传递长消息时采用共享内存的方式，而非消息队列。通过消息队列传递数据需要先copy到内核，然后再到收端，所以有个代价。

**共享内存**

* 使用共享内存很重要的一个原因是共享内存不需要先拷贝到内核空间中，**速度比较快**，共享内存的核心思路就是允许一个或者多个进程所在的虚拟地址空间中映射相同的物理页，从而进行通信。

* 共享内存的实现机制：首先内核会给全局的共享内存维护一个全局的队列结构，这个队列的每一项是一个shmid_kernel结构体与一个IPC key来绑定的，各进程可以通过key来找到并使用同一段共享内存；该进程能否操作这段共享内存时SystemV的权限检查机制来判断；

* 当两个进程同时对一个共享内存建立了映射后，内核会给他们分配两个VMA结构体，进程可以通过他们各自的虚拟地址来访问VMA并访问其背后的共享内存空间。
  ![](http://123.57.190.49:12121/api/image/TRTL04R2.png)

**信号**

* 管道、消息队列、共享内存主要是关注数据传输设计，而信号的作用是**单项的事件通知**能力。一个进程会为一些特定的信号注册回调函数，当进程收到对应的信号后，内核会自动调用该信号的回调函数。
* 信号的发送者可以是其他用户态的进程，但更多的是内核发送通知，用户态一般是使用操作系统提供的API来通知其他进程，如kill等；信号的阻塞提供一个专门的系统调用sigpromask来设置相应的信号掩码。
* 信号需要用sigaction来注册信号，注册的格式是一个sigaction的结构体，结构体包含相应的信号掩码以及回调函数。
* 信号需要考虑其可重入性，比如一个进程收到了一个信号后回调函数由于中断等原因下陷到内核时，又收到了一个相同的信号，这时候可能会重新调用一次该回调函数，因此这种情况下必须保证其可重入性。可重入一般要注意，不使用静态数据，或者静态数据只读；尽量使用本地数据，在使用全局数据时记得加锁；不调用不可重入的函数。
* 好吧，这堆东西看起来很没有意思，现在让我们看一下，linux下支持哪些信号可以使用

---

在终端里，我们会使用`cltr+c`来终止程序。通常会向当前在前台运行的进程（或更准确地说，是前台进程组中的所有进程）发送 `SIGINT` 信号。

好把，这又多出了一堆东西，但在我们搞明白什么是SIGINT什么是前台进程组之前。我们先明白，信号的发送者和接收者。

**信号的发送者**是严格来说，是**内核中的终端驱动程序 (TTY driver)**。它监测到与终端关联的键盘输入 `Ctrl+C`（这是终端的 `intr` 特殊字符，通常默认是 `Ctrl+C`），然后由它负责生成 `SIGINT` 信号。所以，信号的“源头”可以理解为与终端交互的内核部分，它代表了用户的意图。

**接收方**: 当前终端的“前台进程组” (Foreground Process Group) 中的所有进程。前台进程组其实就是前台运行的程序，可能会有疑问，前台不是只能运行一个程序吗。并不是的，例如 `ps aux |  grep ssh`实际上启动了两个程序ps和grep，当然你会说，这两个程序是一先一后运行的，但是如果是`yes | head -n 5`呢，yes是一个一直运行的程序，然后head会因为yes也不听的运行。如果按下cltr + c应该是两个进程都收到SIGINT。

现在让我们回到信号上来。

`SIGINT` 是众多预定义信号中的一种。Linux/Unix 系统定义了大约 31 种标准信号（以及一些实时信号），例如：

* `SIGTERM`: 请求进程终止（比 `SIGKILL` 更礼貌，允许进程清理）。

* `SIGKILL`: 强制终止进程（不能被捕获或忽略）。

* `SIGHUP`: 挂起信号，常用于通知守护进程重新加载配置。

* `SIGUSR1`, `SIGUSR2`: 用户自定义信号，可用于进程间特定的通信目的。

如果这时候你愿意动动脑 ，你就会想到，我在写代码时从来没想过写相关信号的处理逻辑，那我的程序是如何处理这些信号的。那么我们就要提到一个东西了，操作系统。

> 进程同步与通信机制 用于实现进程间互斥、同步和通信所需的信号量等。

我们在上文提到PCB会存储进程通信的相关数据，进程收到信号后的回调函数(我很不喜欢这个名字，让人摸不着头脑)就注册在PCB中。在这个场景中，如果不在程序显式定义接收到SIGINT信号后的触发函数(我喜欢这个表述)，那么会操作系统会为其填上默认的操作，即中断进程。

---

# 2. 线程的基本概念

## 2.1 概述

> 进程是OS进行资源分配和调度的基本单位

上面我们提到了，OS根据进程来进行调度。但是进程调度需要的进行很多切换，好吧，其实也不多，但是人就是这么贪得无厌。调度的具体过程，在第三节叙述。为了能更快的进行调度，线程的概念应运而生，OS将进程视为**资源分配的基本单位**，将线程视为**处理器调度的基本单位**。 线程是操作系统调度执行的最小单位，是进程内的一个执行流。一个进程可以拥有多个线程，这些线程共享进程的资源（如内存空间、文件描述符等）。由于线程共享相同的资源，线程间通信相对简单，可以直接通过共享变量、锁等方式进行。线程相较于进程，上下文切换和调度开销较小。

## 2.2 线程模型

线程有两种实现方式，用户级线程和内核级线程。

> 用户线程是完全在用户空间中实现和管理的线程。它们的创建、同步和调度都由用户级别的线程库（如POSIX线程库，即Pthreads）处理，而不需要内核直接参与。由于用户线程的操作不涉及系统调用，它们的创建和切换开销相对较小。用户线程的一个主要限制是，它们不能充分利用多核处理器的并行能力。因为操作系统调度的基本单位是内核线程，当一个用户线程阻塞时（如I/O操作），整个进程都会被阻塞，即使其他用户线程仍处于就绪状态。这可能导致多处理器系统中的性能下降。

一个简单的理解方式是，我们可以认为OS不认识用户级线程，本质上操作系统认为他在调度进程(我们假设OS只有一个内核级线程，或者该进程的线程全部映射到了一个内核级线程上)，当用户级线程阻塞时，操作系统直接认为进程阻塞了，CPU就被分配给了其他进程。

用户级线程的调度过程：

1. **申请一块栈空间 (Allocate a Stack):** 这是必须的。每个线程都需要有自己的调用栈，用于存放局部变量、函数参数、返回地址等。这块内存是从进程的用户空间地址空间中分配的，就像普通的 `malloc` 或类似的内存分配操作一样。
2. **创建一个线程控制块 (Create a Thread Control Block, TCB):** 这是用户级线程的核心数据结构。线程库需要为新线程创建一个 TCB，用于存储：
   * 线程的状态（如：就绪、运行、阻塞）
   * 线程的寄存器上下文：当线程被暂停时，需要保存它的 CPU 寄存器值（包括程序计数器 PC、栈指针 SP 等），以便将来恢复执行。
   * 指向该线程栈的指针。
   * 线程 ID。
   * 其他线程库管理所需的信息（如在就绪队列中的位置等）。
3. **初始化线程的执行上下文 (Initialize Context):** 在 TCB 中设置好新线程第一次运行时需要恢复的状态。这通常包括：
   * 将程序计数器 (PC) 设置为新线程的**入口函数地址**。
   * 将栈指针 (SP) 设置为刚刚分配的栈的顶部地址。
   * 如果线程需要参数，可能需要将参数放置在栈上或寄存器中，以便入口函数能够访问到。
4. **将线程加入就绪队列 (Add to Ready Queue):** 将新创建的线程的 TCB 加入到用户线程库的就绪队列中，使其有资格在未来的某个时候被用户级调度器选中并执行。

**用户级线程创建的本质：** 主要是在进程的用户空间里分配内存（栈和 TCB），并初始化一个数据结构来代表新的执行流，将其加入到线程库的调度管理中。

> 内核线程是由操作系统内核直接支持和管理的线程。内核负责创建、调度和销毁内核线程，每个内核线程都拥有独立的内核栈和线程上下文。由于内核线程是操作系统调度的基本单位，它们可以充分利用多处理器系统的并行能力。内核线程的缺点是，它们的创建、切换和同步操作涉及系统调用，导致较大的开销。此外，内核线程需要更多的内核资源（如内核栈），这可能在大量线程的情况下导致资源耗尽。

内核级线程，实际上是真正的调度的线程，操作系统只调度内核级线程。

1. **通过系统调用请求创建 (System Call Request):** 用户空间的程序（通常是通过线程库的接口）发起一个系统调用，请求操作系统创建一个新的内核线程。
2. **在内核空间分配资源 (Allocate Kernel Resources):** 操作系统内核接收到系统调用后，会在**内核空间**进行以下主要分配：
   * **分配内核栈 (Allocate a Kernel Stack):** 每个内核线程都需要有一个独立的内核栈，用于在线程执行系统调用、处理中断等进入内核模式时使用。这块内存由内核管理。
   * **创建并初始化一个内核线程控制块 (Create/Initialize a Kernel Thread Control Block, KTCB 或 Task Struct):** 这是操作系统内核用来表示和管理一个线程的核心数据结构。它比用户 TCB 复杂得多，包含：
     * 线程的状态（由内核定义和管理的状态，如 Running, Ready, Blocked, Zombie 等）
     * 线程的寄存器上下文（需要保存用户态和内核态的寄存器值）
     * 指向用户空间栈和内核空间栈的指针
     * 进程 ID 和线程 ID
     * 调度相关信息（优先级、调度策略等）
     * 指向进程数据结构（如页表、文件描述符表等共享资源）的指针
     * 信号处理、资源限制等其他内核管理所需的信息。
3. **设置初始执行上下文 (Set up Initial Execution Context):** 内核会设置 KTCB 中的信息，包括新线程第一次被调度执行时应该从哪里开始（通常是用户指定的入口函数地址），以及它的栈在哪里。
4. **将线程加入内核的就绪队列 (Add to Kernel's Ready Queue):** 内核将新创建的内核线程的 KTCB 加入到操作系统的全局就绪队列中，使其有资格参与操作系统层面的调度，被分配到可用的 CPU 核心上运行。
5. **返回系统调用结果 (Return from System Call):** 内核完成创建操作后，返回到用户空间，告知线程创建是否成功，并返回新线程的 ID。

**内核级线程创建的本质：** 需要通过系统调用请求操作系统内核，由内核在内核空间分配并初始化线程所需的各种资源（包括内核栈和 KTCB），然后将其纳入操作系统的调度管理体系。

另外，补充一点，OS的内核级线程数量，主要受资源和配置的限制，理论上无限的资源，可以创建无数个内核级线程。

### 2.2.1 多对一模型

多对一模型就是多个用户级线程对应一个内核级线程，在这种模型下，一个进程中的所有用户线程都运行在同一个底层内核线程上。这种情况下，操作系统看来，他是在调度一个进程。一旦某个用户级线程阻塞，他会导致整个进程阻塞，进而让出CPU。因为OS没办法，让该进程的其他线程运行起来。

当然并不是说这种方案一无是处，我们假设我们的代码写的很好，反而这种方案并不差，因为用户空间内切换线程是十分简单而且代价小的，实际上，相当于切换到另一处去执行代码，只需要进程的用户空间里分配内存（栈和 TCB），并初始化一个数据结构来代表新的执行流，将其加入到线程库的调度管理中。

### 2.2.2 一对一模型

一对一模型就更简单了，一个用户级线程对应一个内核级线程，那这种情况下OS会接管线程的调度，这种模型实现简单，但是因为内核级线程切换代价比用户级线程大（看吧，人们就是贪得无厌的，进程调度觉得代价大，内核级线程调度也觉得代价大）。

### 2.2.3 多对多模型

如果你学过计算机，你会发现计算机的人，也是喜欢折中的，既然多对一和一对一都有问题(什么，你问一对多呢？这么奢侈吗，一个用户线程对多个内核线程，你是真正的圣人，乐山大佛可以换你来。)，那不如多对多吧，多个用户级线程对应多个内核级线程，这样，既可以使用用户级线程代价小的切换，又可以使用内核级线程的对多处理器的并行能力的利用，当然，总有点缺点，那就是怎么来调度，但这反正对上层程序员是屏蔽的，操作系统的程序员和线程库程序员会解决这个问题，头发又不是掉自己的，谁会心疼呢？

## 2.3 Linux中的实际线程

这里我们看一下Linux的内核级线程(为什么不看用户级线程，因为我不想看不同的线程库是怎么实现的)

Linux 在内核层面有一个独特的设计：它没有像某些其他操作系统那样严格区分“进程”和“线程”的抽象概念。在 Linux 内核内部，基本的调度和管理单位是 **“任务 (Task)”**。嘿嘿，气不气，这就是计算机的乐趣，你永远不知道别人是怎么想的，你别管我是内部怎么实现，你就说外面看上去是不是你要的样子，金玉其外，败絮其中。

一个“任务”可以代表一个传统的进程，也可以代表一个线程。传统的进程和线程在 Linux 内核看来，是共享程度不同的“任务”。

下面给出Gemini总结的内容

---

### `clone()` 系统调用

这是 Linux 中创建任务（包括进程和线程）的基础系统调用。`clone()` 比传统的 `fork()`（创建进程）或 `create_thread` 更通用，它允许调用者精确地控制新创建的任务与父任务之间共享哪些资源，哪些资源是独立的。

通过 `clone()` 系统调用时传入不同的标志位，可以实现不同的效果：

* 如果指定了大量的共享标志（例如共享内存空间 `CLONE_VM`、文件描述符表 `CLONE_FILES`、信号处理程序 `CLONE_SIGHAND` 等），那么创建出的新任务就表现得像一个**线程**，它与父任务共享同一个地址空间，可以访问父任务的数据。
* 如果不指定或指定很少的共享标志（特别是内存空间不共享），那么创建出的新任务就表现得像一个独立的**进程**，它有自己的独立地址空间（通过写时复制实现）。

### Linux 中的内核级线程实现（NPTL）

现代 Linux 系统广泛使用 **NPTL (Native POSIX Thread Library)** 作为其标准的 POSIX 线程库。NPTL 库内部就是基于 `clone()` 系统调用实现的，并且它采用了之前提到的 **一对一 (One-to-One, 1:1)** 线程模型。

这意味着：

1. 当你使用像 `pthread_create()` 这样的 NPTL 函数创建一个用户级线程时，NPTL 库会在内部调用 `clone()` 系统调用。
2. 这个 `clone()` 调用会带上标志位，指示新创建的“任务”需要与父进程共享内存空间、文件描述符等资源。
3. **操作系统内核**接收到这个请求，就会创建一个新的**内核任务**。
4. 这个新的内核任务拥有自己独立的任务结构体、独立的内核栈、独立的寄存器上下文等，但它与父进程的其他任务共享内存地址空间。
5. 从操作系统的调度器来看，这个新创建的内核任务就是一个独立的、可调度的执行单元，它与其他进程的任务或同进程内的其他线程（内核任务）地位平等。

### Linux 内核级线程的特点 (基于 Task + NPTL 的 1:1 模型)

* **是内核的调度单元：** 每个由 `pthread_create()` 创建的线程都对应一个独立的内核任务，操作系统可以直接调度这些任务到任何可用的 CPU 核心上运行。
* **共享进程资源：** 同一个进程内的所有内核任务（线程）共享进程的地址空间、文件描述符表、信号处理方式等资源。
* **独立的执行上下文：** 每个内核任务有自己的独立的程序计数器、栈指针、寄存器集以及内核栈。
* **阻塞不影响其他线程：** 如果一个线程执行了阻塞的系统调用，只会阻塞它对应的那个内核任务，而同一个进程中的其他线程（对应着其他内核任务）可以继续在其他 CPU 核心上运行。
* **由内核管理：** 线程的创建、终止、同步原语（如互斥锁、条件变量在大部分情况下的实现）都依赖于内核提供的机制（如 `futex` 等系统调用）。
* **相较于 M:1 用户线程开销更大：** 创建和上下文切换需要通过系统调用进入内核，开销比完全在用户空间进行的用户级线程操作要高。

---

总结就是1:1模型，最简单的方案。太对了，就应该这样，至于性能开销，可以去压榨一下做芯片的。

# 3. 进程的调度

> ### 调度的层次
> 
> **作业调度：**
> 
> 作业调度也即高级调度，这个阶段可以看作是准备阶段。主要任务是按照一定的规则从外存上处于后备队列的作业中挑选一个或多个作业，为其分配内存，建立 PCB（进程） 等，使它们具备竞争处理机的能力。
> 
> 这个阶段进程的状态变化是：无 --> 创建态 --> 就绪态
> 
> **内存调度：**
> 
> 内存调度也即中级调度，这个阶段可以看作是优化阶段。主要任务是将暂时不能运行的进程对换到外存中，使它们挂起；而当挂起的进程具备运行条件时，它们会被重新对换回内存，得到激活。这个阶段的主要目的是提高内存利用率和系统吞吐量。
> 
> 这个阶段进程的状态变化是： 静止就绪态 --> 活动就绪态，静止阻塞态 --> 活动阻塞态
> 
> **进程调度：**
> 
> 进程调度即低级调度，这个阶段让进程真正运行起来。主要任务是按照某种算法，从就绪队列中选取一个进程，分配处理机给它。进程调度是最基本、次数最频繁的阶段。
> 
> 这个阶段进程的状态变化是： 就绪态 --> 活动态

## 3.1 进程的调度过程

进程调度主要涉及从“就绪”到“运行”，以及从“运行”到“就绪”或“阻塞”的状态迁移。

**一个简化的调度循环流程：**

1. **进程创建/加载：** 新进程被创建，进入“就绪”状态，被放到就绪队列中。
2. **调度器选择：** 操作系统调度器（Scheduler）从就绪队列中选择一个进程。选择哪个进程取决于调度算法（如先来先服务、短作业优先、时间片轮转、优先级调度等）。
3. **上下文切换（调度出）：** 操作系统需要暂停当前正在 CPU 上运行的进程（如果有没有正在运行的进程，则跳过此步），并保存其当前的执行状态。
4. **上下文切换（调度入）：** 操作系统加载第二步选中的那个进程的执行状态到 CPU 中。
5. **进程运行：** CPU 开始执行新选中的进程的指令，进程进入“运行”状态。
6. **运行中断：** 进程运行一段时间后，会因为某个事件而暂停执行，将 CPU 让出来。这可能是：
   * **自愿让出 CPU (Voluntary Yield):** 进程需要等待 I/O 完成，或者需要等待某个同步事件，它会发起一个**系统调用**（如读文件、等待信号量）。这时进程进入“阻塞”状态。
   * **时间片耗尽 (Time Slice Expiration):** 在支持时间片轮转的系统中，进程运行达到预设的时间长度，由一个**时钟中断**触发，进程被强制暂停。这时进程进入“就绪”状态，重新回到就绪队列。
   * **更高优先级进程就绪 (Higher Priority Process Ready):** 在优先级调度系统中，一个更高优先级的进程从阻塞状态变为就绪状态，这可能由一个**I/O 完成中断**或其他事件触发。操作系统可能会抢占当前正在运行的低优先级进程，将其置为“就绪”状态。
   * **进程终止 (Process Termination):** 进程完成任务或发生不可恢复的错误，发起**系统调用**请求终止。进程进入“终止”状态。
7. **重新调用调度器：** 当进程从“运行”状态离开时，操作系统会重新调用调度器，回到步骤 2，选择下一个要运行的进程。
8. **事件完成（唤醒）：** 当一个阻塞的进程等待的事件发生时（例如，磁盘读取完成），由一个**中断**（如 I/O 完成中断）通知操作系统。操作系统将该进程的状态从“阻塞”改为“就绪”，并将其放回就绪队列，使其有机会再次被调度执行。

进程的上下文切换是最消耗时间的过程，进程的上下文切换主要做的事情如下：

1. **保存寄存器状态：** 操作系统内核会将当前正在 CPU 上执行的进程的**所有重要寄存器**的值保存到该进程的**进程控制块 (Process Control Block, PCB)** 中。这些寄存器包括：
   * **通用寄存器 (General-purpose Registers):** 用于存储数据和计算结果。
   * **程序计数器 (PC) 或指令指针 (IP):** 指向进程下一条要执行的指令的地址。这是最关键的，因为它决定了进程下次从哪里开始执行。
   * **栈指针 (SP):** 指向当前进程用户栈的顶部。
   * **程序状态字 (PSW) 或标志寄存器 (Flags Register):** 包含条件码、控制标志等信息。
   * **内存管理寄存器 (Memory Management Registers):** 非常重要！特别是**页表基址寄存器**。对于不同的进程（拥有不同的地址空间），OS 需要保存当前进程的页表信息，并在切换时加载新进程的页表信息，以便 CPU 正确访问新进程的内存。
   * 其他一些控制寄存器。
2. **更新 PCB 状态：** 操作系统更新该进程在 PCB 中的状态，将其改为“就绪”或“阻塞”。
3. **将 PCB 放入相应队列：** 根据新的状态，将进程的 PCB 放到就绪队列或等待队列中。

**当一个进程被调度到 CPU 上运行时（恢复上下文）：**

1. **操作系统调度器选择进程：** 调度器从就绪队列中选择一个进程的 PCB。
2. **加载内存管理寄存器：** 操作系统首先加载新选中的进程的**页表基址寄存器**和其他内存管理相关的寄存器。这使得 CPU 现在能够访问新进程的地址空间。
3. **加载其他寄存器状态：** 操作系统从该进程的 PCB 中读取之前保存的所有寄存器值（通用寄存器、PC、SP、PSW 等）。
4. **加载到 CPU 寄存器中：** 将这些值加载到 CPU 的相应寄存器中。
5. **切换到用户模式并跳转：** 操作系统执行一条特殊的指令，将 CPU 从内核模式切换回用户模式，并将 CPU 的执行流跳转到刚刚从 PCB 中加载的**程序计数器 (PC)** 所指向的地址。

## 3.2 进程的调度算法

这里给出对用户和进程而言，他们能够感知到的时间：

* **平均周转时间：** 周转时间指`作业完成时间 - 作业提交时间 = 作业实际运行的时间 + 等待时间`，平均周转时间 `各作业周转时间之和 / 作业数`

* **平均等待时间：** 等待时间指进程或者作业处于等待处理机状态的时间之和，即 `周转时间 - 作业实际运行的时间`，平均等待时间指的是 `各作业等待时间之和 / 作业数`

* **平均响应时间：** 响应时间指的从用户提交请求到首次产生响应所用的时间，平均响应时间指的是`各作业响应时间之和/作业数`

进程的调度算法，负责从就绪队列中选择一个进程分配CPU。进程的调度算法的终极目标是，提高CPU利用率。并尽可能的让这几个时间最短。（不同的OS有不同的追求，所以三个时间不一定同时最低）

进程的调度算法，其实总体上看也就两种，优先级和时间片轮转，当然从是否抢占上，也能分成抢占式和非抢占式。

### 3.2.1 优先级调度

#### 3.2.1.1 先来先得

先来先得服务，其实就是将进程到达的时间作为优先级，先到的进程先分配CPU，这种方案主打三件事，公平！公平！还是他妈的公平！这个策略的问题在于**对短任务不友好**，假设前面排着一个长任务，那么这个短任务要等很久，本来它只用很短的时间就执行完了，但现在它的周转时间会变得很长；同样**对IO密集型也不友好**，当IO密集型需要读写IO而进入阻塞让出CPU时，假设后序是一个长时间运行的任务，那么当IO读写完了也需要等待很长时间；而且它根本就没有考虑响应时间，**对交互式任务很不友好**。

#### 3.2.1.2 最短时间优先

最短时间优先是将进程的运行时间作为优先级，运行时间越短，越早拿到CPU，这种方式，可以降低平均等待时间。但是这种方式有个问题，一是进程的运行时间不好确定，另一个是，对于运行时间长的进程可能会饥饿，拿不到CPU。

#### 3.2.1.3 最短完成时间优先

最短完成时间优先将进程的剩余完成时间作为优先级，剩余完成时间越短，越早拿到CPU。与最短时间优先相比，其实就是最短完成时间是抢占式的，而最短时间是非抢占的。以下面这个例子举例，假设一个进程需要运行10min，已经在CPU上运行了3min，那么他还剩下7min，这时候，来了一个5min的进程，如果SJB则会进入等待队列，而STCF则会直接一把抢过(没有炼化)，抢占CPU。这种方式，一样会导致饥饿。

#### 3.2.1.4 多级队列

多级队列其实也是一种优先级调度，优先级是各个队列，不同的队列有不同的优先级。各个队列之内的调度方式有可以设置不同调度方案。

* MLQ是一种高效的优先级调度策略，但是从另一个角度说，它依然没有解决**低优先级的饥饿问题**。如果高优先级的任务数量很多，那么低优先级永远也不会去执行。
* 同时优先级固定也会带来一个叫做**优先级反转**的问题，比如有任务A,B,C，优先级依次从高到低，然后此时C恰好持有一把锁，A也想获得这把锁，但是因为C先拿走了，所以A此时只能进入阻塞状态等C放锁；然后因为B比C优先级高，所以B先运行，那么此时就有B比A优先级高的一个假象。一般来说解决这类问题的思路是**优先级继承**，也就是A暂时把它的优先级转移给C，让C先完成，这样A就能接着完成。

### 3.2.2 时间片轮转

用户体验最直接的指标就是响应时间，现代的操作系统调度一般都是采用**时间片轮转**的思路，也就是将CPU划分为一个一个时间片，每个任务独占CPU的一个时间片，如果时间片设置的足够小，那么每个任务都会在一定的时间内执行并响应用户；对于RR策略来说，**时间片大小的选取**是需要考虑的问题，时间片选的越小，那么任务响应的时间就越快，但是这意味着调度的次数会增加，调度的开销就大。这个策略的弊端是**任务的平均周转时间比较高**，因为所有任务是平分CPU资源的，从这个角度来说**RR策略保证了任务的公平性**，但是公平必然会损失性能。

### 3.2.3 多级反馈队列

* 具体的策略是，**短任务具有更高的优先级**，这样主要是为了降低平均周转时间；IO密集型的任务因为其CPU运行时间比较短，所以它的优先级一般也比较高，有利于提高IO资源的利用率；交互式任务一般是短任务，所以其优先级一般也比较高。
* 在真实系统中，可能无法去预测是短任务还是长任务，因此需要动态的去调整，当任务第一次进入运行队列时，系统会假定该任务是最高优先级，如果该任务运行时间超过**最大运行时间**，那么系统自动会给其降低优先级。
* 为了缓解低优先级的饥饿问题，调度器会定时的将所有低优先级的队列重新提到最高。保证低优先级有机会执行。
* 多级队列的出最后一个队列外，通常使用RR来做内部调度，通常高优先级队列的时间片短，而低优先级的队列时间片长，优先级最低的队列使用FCFS调度。

# 4. 同步与异步

> * 并发关注在一个时间段内处理多个任务，而并行关注在同一时刻执行多个任务。
> * 并发适用于单处理器或单核心系统，通过任务调度实现多任务处理；并行则依赖于多处理器或多核心系统来实现任务的同时执行。
> * 并发主要用于提高系统的响应速度和吞吐量，而并行则旨在加速任务的完成速度。

我想并行和并发的区别不需要再赘述了。

同步和异步主要是解决并行和并发之间，不同进程的执行顺序问题。

> * 同步（Synchronous）：在同步操作中，调用者发起一个请求后，需要等待被调用者处理完毕并返回结果，期间调用者不能进行其他操作。换句话说，调用者与被调用者的执行是串行的。同步操作的典型例子是普通的函数调用。
> * 异步（Asynchronous）：在异步操作中，调用者发起一个请求后，无需等待被调用者处理完毕，可以继续执行其他操作。被调用者在处理完请求后，通常通过回调函数、事件或消息队列等方式通知调用者结果。换句话说，调用者与被调用者的执行是并行的。异步操作的典型例子是JavaScript中的Ajax请求。

执行顺序，实际上决定了进程之间对共享资源的使用，实际上，如果两个线程不共享任何资源，那无所谓同步异步，你随意执行，管我啥事，管你啥事。

## 4.1 常见的同步机制

* **互斥锁（Mutex）**：当一个线程获得互斥锁并访问共享资源时，其他试图获得该锁的线程将被阻塞，直到锁被释放。互斥锁可以保证同一时刻只有一个线程能够访问共享资源。
  
  * **自旋锁（Spinlock）**： 自旋锁是一种低级的同步原语，通常用于多处理器或多核系统中。与互斥锁不同，当一个线程尝试获得自旋锁时，如果锁已经被其他线程持有，它将不断循环（“自旋”）检查锁是否可用，而不是进入阻塞状态。自旋锁适用于锁持有时间较短且线程不希望在等待锁时进入睡眠状态的场景。自旋锁的底层实现通常依赖于原子操作和CPU指令，如测试和设置（test-and-set）或比较和交换（compare-and-swap）等。
  
  * **乐观锁和悲观锁：**
    
    * 乐观锁：乐观锁在操作数据时非常乐观，认为别人不会同时修改数据。因此乐观锁不会上锁，只是在执行更新的时候判断一下在此期间别人是否修改了数据：如果别人修改了数据则放弃操作，否则执行操作。
    * 悲观锁：悲观锁在操作数据时比较悲观，认为别人会同时修改数据。因此操作数据时直接把数据锁住，直到操作完成后才会释放锁；上锁期间其他人不能修改数据。

* **读写锁（Read-Write Lock）**： Linux中的读写锁也是通过POSIX线程库（pthread）实现的。读写锁允许多个线程同时进行读操作，但在进行写操作时，只允许一个线程访问共享资源。

* **条件变量（Condition Variables）**： 条件变量用于实现线程间的同步。当一个线程需要等待某个条件满足时，它可以使用条件变量进入休眠状态，直到另一个线程更改共享资源并通知条件变量。条件变量通常与互斥锁一起使用。

* **信号量（Semaphore）**： 信号量是一种用于实现多线程和多进程同步的计数器。信号量用于限制对共享资源的访问数量。PV操作

## 4.2 常见的同步和互斥问题

### 4.2.1 生产者消费者问题

### 4.2.3 哲学家就餐问题

# 5. 死锁

## 5.1 概念

> 死锁是指在多线程或多进程环境中，一组或多组线程/进程互相等待彼此持有的资源，导致这些线程/进程无法继续执行的情况。当死锁发生时，受影响的线程/进程无法完成任务，系统性能和吞吐量可能会受到严重影响。

死锁不是死循环，死循环起码这几个任务还在运行，死锁会导致CPU根本不执行这几个死锁的任务。

## 5.2 死锁的必要条件

> * **互斥条件（Mutual Exclusion）**：一个资源在同一时间只能被一个线程或进程占用。
> * **占有且等待条件（Hold and Wait）**：一个线程或进程在持有至少一个资源的同时，仍然尝试获取其他线程或进程所持有的资源。
> * **不可抢占条件（No Preemption）**：资源不能被强行从一个线程或进程中抢占，只能由占有它的线程或进程主动释放。
> * **循环等待条件（Circular Wait）**：存在一个线程/进程等待序列，其中每个线程/进程都在等待下一个线程/进程所持有的资源。

占有并等待和不可抢占的区别，其实再主被动上，不主动放弃叫占有并等待，不能被被人抢走叫不可抢占。

## 5.3 死锁预防

破坏四个条件之一，使其无法进入死锁状态。

### 5.3.1 破坏互斥

这个方案非常简单，但是基本无法实现，即让资源变成共享的。但是基本上不可能实现。

### 5.3.2 破坏占有并等待

破坏占用并等待的一种方法是，进程在运行前申请全部的资源；另一种方法是，进程只获得运行初期需要的资源，便开始运行，在运行过程中逐步释放掉分配到，已经使用完毕的资源，然后再去请求新的资源。

### 5.3.3 破坏不可抢占

当一个已经持有了一些资源的进程在提出新的资源请求没有得到满足时，它必须释放已经保持的所有资源，待以后需要使用的时候再重新申请。这就意味着进程已占有的资源会被短暂的释放或者说被抢占了。

### 5.3.4 破坏循环等待

过定义资源类型的线性顺序来预防，可以将每个资源编号，当一个进程占有编号为i 的资源时，那么它下一次申请资源只能申请编号大于i 的资源。

## 5.4 死锁避免

进行资源分配时，进行检测，避免进入可能死锁的危险状态。

死锁避免的主要算法时银行家算法。

银行家算法为整个系统规定了两种状态：

* 安全状态：可以找到一个进程执行顺序，进程按序执行后，每个进程均可以顺利完成

* 不安全状态： 找不到可以执行的序列。不安全状态不代表会进入死锁，而是有进入死锁的可能。

银行家算法的实质就是**要设法保证系统动态分配资源后不进入不安全状态，以避免可能产生的死锁。** 即没当进程提出资源请求且系统的资源能够满足该请求时，系统将判断满足此次资源请求后系统状态是否安全，如果判断结果为安全，则给该进程分配资源，否则不分配资源，申请资源的进程将阻塞。

银行家算法的执行有个前提条件，即要求进程预先提出自己的最大资源请求，并假设系统拥有固定的资源总量。下面介绍银行家算法所用的主要的数据结构。

银行家算法的流程如下：

* 初始化：
  
  * 初始化资源向量available，它记录系统中各个资源的当前可用数目
  
  * 最大需求矩阵max，它记录每个进程对各类资源的最大需求量
  
  * 分配矩阵allocation，它记录当前为每个进程分配的各类资源的数量
  
  * 需求矩阵need，它记录了当前各个进程对各类资源的需求数量

* 进程请求资源，进程给出它的请求向量request，来表示自己对系统资源的请求。

* 判断(假设$P_i$ 发出了向量$request_i$)
  
  1. 若$request_i > need_i$则出错，说明进程申请了它不需要的资源
  
  2. 若$request_i > available$，出错，说明进程申请的资源，系统无法提供
  
  3. 将$allocation_i += request_i$，$available -= request_i $，$need_i -= request_i$
  
  4. 系统执行安全检查算法
  
  5. 如通过安全检查，则为$P_i$分配$request_i$的资源
  
  6. 如未通过安全检查，则撤销3中的操作，不分配资源

* 安全检查算法：
  
  * 初始化：初始化work = available，finish = flash，finish为一个bool类型的数组，其中$finish_i$表示进程$P_i$是否已经加入安全队列
  
  * 按照进程编号寻找$need_i < work \&\& finish_i \neq true $的进程，假设该进程不久完成任务并归还资源，于是$work=work+need_i, finish_i=true$。重复这一流程，知道无法找到符合条件的进程
  
  * 如果finish数组全部为true，则通过安全检查，反正则不通过。

## 5.5 死锁检测与恢复

检测出死锁状态，并进行恢复

死锁检测算法有两种，资源图法和检测算法。

检测算法的流程和银行家算法的安全检查算法相同。

资源图法是将进程和资源全部变为节点，其中资源节点中，包含系统现在的多个资源。图中的边是有向边，进程->资源的边表示进程申请资源，一条边代表进程申请一个资源，资源->进程的边，表述已经为进程分配的资源，一条边表示分配一个。逐渐删除所有的边，如果边可以全部删除，则没有死锁。具体如图。
